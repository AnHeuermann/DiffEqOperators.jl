var documenterSearchIndex = {"docs":
[{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/#Heat-equation","page":"Examples","title":"Heat equation","text":"","category":"section"},{"location":"examples/#Dirichlet-boundary-conditions","page":"Examples","title":"Dirichlet boundary conditions","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using ModelingToolkit, DiffEqOperators\n# Method of Manufactured Solutions: exact solution\nu_exact = (x,t) -> exp.(-t) * cos.(x)\n\n# Parameters, variables, and derivatives\n@parameters t x\n@variables u(..)\n@derivatives Dt'~t\n@derivatives Dxx''~x\n\n# 1D PDE and boundary conditions\neq  = Dt(u(t,x)) ~ Dxx(u(t,x))\nbcs = [u(0,x) ~ cos(x),\n        u(t,0) ~ exp(-t),\n        u(t,1) ~ exp(-t) * cos(1)]\n\n# Space and time domains\ndomains = [t ∈ IntervalDomain(0.0,1.0),\n        x ∈ IntervalDomain(0.0,1.0)]\n\n# PDE system\npdesys = PDESystem(eq,bcs,domains,[t,x],[u])\n\n# Method of lines discretization\ndx = 0.1\norder = 2\ndiscretization = MOLFiniteDifference(dx,order)\n\n# Convert the PDE problem into an ODE problem\nprob = discretize(pdesys,discretization)\n\n# Solve ODE problem\nusing OrdinaryDiffEq\nsol = solve(prob,Tsit5(),saveat=0.2)\n\n# Plot results and compare with exact solution\nx = prob.space[2]\nt = sol.t\n\nusing Plots\nplt = plot()\nfor i in 1:length(t)\n    plot!(x,Array(prob.extrapolation[1](t[i])*sol.u[i]),label=\"Numerical, t=$(t[i])\")\n    scatter!(x, u_exact(x, t[i]),label=\"Exact, t=$(t[i])\")\nend\ndisplay(plt)","category":"page"},{"location":"examples/#Neumann-boundary-conditions","page":"Examples","title":"Neumann boundary conditions","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using ModelingToolkit, DiffEqOperators\n# Method of Manufactured Solutions: exact solution\nu_exact = (x,t) -> exp.(-t) * cos.(x)\n\n# Parameters, variables, and derivatives\n@parameters t x\n@variables u(..)\n@derivatives Dt'~t\n@derivatives Dx'~x\n@derivatives Dxx''~x\n\n# 1D PDE and boundary conditions\neq  = Dt(u(t,x)) ~ Dxx(u(t,x))\nbcs = [u(0,x) ~ cos(x),\n        Dx(u(t,0)) ~ 0.0,\n        Dx(u(t,1)) ~ -exp(-t) * sin(1)]\n\n# Space and time domains\ndomains = [t ∈ IntervalDomain(0.0,1.0),\n        x ∈ IntervalDomain(0.0,1.0)]\n\n# PDE system\npdesys = PDESystem(eq,bcs,domains,[t,x],[u])\n\n# Method of lines discretization\n# Need a small dx here for accuracy\ndx = 0.01\norder = 2\ndiscretization = MOLFiniteDifference(dx,order)\n\n# Convert the PDE problem into an ODE problem\nprob = discretize(pdesys,discretization)\n\n# Solve ODE problem\nusing OrdinaryDiffEq\nsol = solve(prob,Tsit5(),saveat=0.2)\n\n# Plot results and compare with exact solution\nx = prob.space[2]\nt = sol.t\n\nusing Plots\nplt = plot()\nfor i in 1:length(t)\n    plot!(x,Array(prob.extrapolation[1](t[i])*sol.u[i]),label=\"Numerical, t=$(t[i])\")\n    scatter!(x, u_exact(x, t[i]),label=\"Exact, t=$(t[i])\")\nend\ndisplay(plt)","category":"page"},{"location":"examples/#Robin-boundary-conditions","page":"Examples","title":"Robin boundary conditions","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using ModelingToolkit, DiffEqOperators \n# Method of Manufactured Solutions\nu_exact = (x,t) -> exp.(-t) * sin.(x)\n\n# Parameters, variables, and derivatives\n@parameters t x\n@variables u(..)\n@derivatives Dt'~t\n@derivatives Dx'~x\n@derivatives Dxx''~x\n\n# 1D PDE and boundary conditions\neq  = Dt(u(t,x)) ~ Dxx(u(t,x))\nbcs = [u(0,x) ~ sin(x),\n        u(t,-1.0) + 3Dx(u(t,-1.0)) ~ exp(-t) * (sin(-1.0) + 3cos(-1.0)),\n        u(t,1.0) + Dx(u(t,1.0)) ~ exp(-t) * (sin(1.0) + cos(1.0))]\n\n# Space and time domains\ndomains = [t ∈ IntervalDomain(0.0,1.0),\n        x ∈ IntervalDomain(-1.0,1.0)]\n\n# PDE system\npdesys = PDESystem(eq,bcs,domains,[t,x],[u])\n\n# Method of lines discretization\n# Need a small dx here for accuracy\ndx = 0.05\norder = 2\ndiscretization = MOLFiniteDifference(dx,order)\n\n# Convert the PDE problem into an ODE problem\nprob = discretize(pdesys,discretization)\n\n# Solve ODE problem\nusing OrdinaryDiffEq\nsol = solve(prob,Tsit5(),saveat=0.2)\n\n# Plot results and compare with exact solution\nx = prob.space[2]\nt = sol.t\n\nusing Plots\nplt = plot()\nfor i in 1:length(t)\n    plot!(x,Array(prob.extrapolation[1](t[i])*sol.u[i]),label=\"Numerical, t=$(t[i])\")\n    scatter!(x, u_exact(x, t[i]),label=\"Exact, t=$(t[i])\")\nend\ndisplay(plt)","category":"page"},{"location":"#DiffEqOperators.jl","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Construct high-order finite-difference operators to discretize a partial differential equation and its boundary conditions by the method of lines. This reduces it to a system of ordinary differential equations that can be solved by DifferentialEquations.jl.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Both centered and upwind operators are provided, for domains of any dimension, arbitrarily spaced grids, and for any order of accuracy. The cases of 1, 2, and 3 dimensions with an evenly spaced grid are optimized with a convolution routine from NNlib.jl. Care is taken to avoid unnecessary allocations.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Any operator can be concretized as an Array, a BandedMatrix or a sparse matrix.","category":"page"},{"location":"#The-simplest-case","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"The simplest case","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"As shown in the figure, the operators act on a set of samples f_j = f(x_j) for a function f at a grid of points x_j. The grid has n interior points at x_j = jh for j = 1 to n, and 2 boundary points at x_0 = 0 and x_{n+1} = (n+1) h. The input to the numerical operators is a vector u = [f_1, f_2, …, f_N], and they output a vector of sampled derivatives du ≈ [f'(x_1), f'(x_2), …, f'(x_N)], or a higher-order derivative as requested.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"A numerical derivative operator D of order m can be constructed for this grid with D = CenteredDifference(1, m, h, n). The argument 1 indicates that this is the first derivative. Order m means that the operator is exact up to rounding when f is a polynomial of degree m or lower.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The derivative operator D is used along with a boundary condition operator Q to compute derivatives at the interior points of the grid. A simple boundary condition f(x_0) = f(x_n+1) = 0 is constructed with Q = Dirichlet0BC(eltype(u)).","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Given these definitions, the derivatives are calculated as if the operators D and Q were matrices, du = D*Q*u. This is an abuse of notation! The particular Q in this example is a linear operator but, in general, boundary conditions are affine operators. They have the form Q(x) = M*x + c, where M is a matrix and c is a constant vector. As a consequence, Q cannot be concretized to a matrix.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"(Image: Actions of DiffEqOperators on interior points and ghost points)","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The operator D works by interpolating a polynomial of degree m through m+1 adjacent points on the grid. Near the middle of the grid, the derivative is approximated at x_j by interpolating a polynomial of order m with x_j at its centre. To define an order-m polynomial, values are required at m+1 points. When x_j is too close to the boundary for that to fit, the polynomial is interpolated through the leftmost or rightmost m+1 points, including two “ghost” points that Q appends on the boundaries. The numerical derivatives are linear combinations of the values through which the polynomials are interpolated. The vectors of the coefficients in these linear combinations are called “stencils”. Because D takes values at the ghost points and returns values at the interior points, it is an n×(n+2) matrix.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The boundary condition operator Q acts as an (n+2)×n matrix. The output Q*u is a vector of values on the n interior and the 2 boundary points, [a, f(x_1), …, f(x_N), b]. The interior points take the values of u. The values a and b are samples at “ghost” points on the grid boundaries. As shown, these values are assigned so that an interpolated polynomial P(x) satisfies the left hand boundary condition, and Q(x) satisfies the right-hand boundary condition. The boundary conditions provided by the library are precisely those for which the values a and b are affine functions of the interior values f_j, so that Q is an affine operator.","category":"page"},{"location":"#Higher-dimensions","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Higher dimensions","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"In one dimension, u is naturally stored as a Vector, and the derivative and boundary condition operators are similar to matrices.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"In two dimensions, the values f(x_j) are naturally stored as a matrix. Taking derivatives along the downwards axis is easy, because matrices act columnwise. Horizontal derivatives can be taken by transposing the matrices. The derivative along the rightward axis is (D*F')' = F*D'. This is easy to code, but less easy to read for those who haven't seen it before.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"When a function has three or more arguments, its values are naturally stored in a higher-dimensional array. Julia's multiplication operator is only defined for Vector and Matrix, so applying an operator matrix to these arrays would require a complicated and error prone series of reshape and axis permutation functions.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Therefore the types of derivative and boundary condition operators are parameterised by the axis along which the operator acts. With derivative operators, the axis is supplied as a type parameter. The simple case CenteredDifference(…) is equivalent to CenteredDifference{1}(…), row-wise derivatives are taken by CenteredDifference{2}(…), sheet-wise by CenteredDifference{3}(…), and along the Nth axis by CenteredDifference{N}(…).","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Boundary conditions are more complicated. See @doc MultiDimBC for how they are supposed to work in multiple dimensions. They don't currently work that way.","category":"page"},{"location":"#Constructors","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Constructors","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The constructors are as follows:","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"CenteredDifference{N}(derivative_order::Int,\n                      approximation_order::Int, dx,\n                      len::Int, coeff_func=nothing)\n\nUpwindDifference{N}(derivative_order::Int,\n                    approximation_order::Int, dx\n                    len::Int, coeff_func=nothing)","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The arguments are:","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"N: The directional dimension of the discretization. If N is not given, it is assumed to be 1, i.e., differencing occurs along columns.\nderivative_order: the order of the derivative to discretize.\napproximation_order: the order of the discretization in terms of O(dx^order).\ndx: the spacing of the discretization. If dx is a Number, the operator is a uniform discretization. If dx is an array, then the operator is a non-uniform discretization.\nlen: the length of the discretization in the direction of the operator.\ncoeff_func: An operational argument for a coefficient function f(du,u,p,t) which sets the coefficients of the operator. If coeff_func is a Number, then the coefficients are set to be constant with that number. If coeff_func is an AbstractArray with length matching len, then the coefficients are constant but spatially dependent.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"N-dimensional derivative operators need to act against a value of at least N dimensions.","category":"page"},{"location":"#Derivative-Operator-Actions","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Derivative Operator Actions","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"These operators are lazy, meaning the memory is not allocated. Similarly, the operator actions * can be performed without ever building the operator matrices. Additionally, mul!(y,L,x) can be performed for non-allocating applications of the operator.","category":"page"},{"location":"#Concretizations","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Concretizations","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The following concretizations are provided:","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Array\nSparseMatrixCSC\nBandedMatrix\nBlockBandedMatrix","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Additionally, the function sparse is overloaded to give the most efficient matrix type for a given operator. For one-dimensional derivatives this is a BandedMatrix, while for higher-dimensional operators this is a BlockBandedMatrix. The concretizations are made to act on vec(u).","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"A contraction operator concretizes to an ordinary matrix, no matter which dimension the contraction acts along, by doing the Kronecker product formulation. I.e., the action of the built matrix will match the action on vec(u).","category":"page"},{"location":"#Boundary-Condition-Operators","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Boundary Condition Operators","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Boundary conditions are implemented through a ghost node approach. The discretized values u should be the interior of the domain so that, for the boundary value operator Q, Q*u is the discretization on the closure of the domain. By using it like this, L*Q*u is the NxN operator which satisfies the boundary conditions.","category":"page"},{"location":"#Periodic-Boundary-Conditions","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Periodic Boundary Conditions","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The constructor PeriodicBC provides the periodic boundary condition operator.","category":"page"},{"location":"#Robin-Boundary-Conditions","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Robin Boundary Conditions","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The variables in l are [αl, βl, γl], and correspond to a BC of the form al*u(0) + bl*u'(0) = cl, and similarly r for the right boundary ar*u(N) + br*u'(N) = cl.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"RobinBC(l::AbstractArray{T}, r::AbstractArray{T}, dx::AbstractArray{T}, order = one(T))","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Additionally, the following helpers exist for the Neumann u'(0) = α and Dirichlet u(0) = α cases.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"DirichletBC(αl::T, αr::T)\nDirichlet0BC(T::Type) = DirichletBC(zero(T), zero(T))","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"This fixes u = αl at the first point of the grid, and u = αr at the last point.","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Neumann0BC(dx::Union{AbstractVector{T}, T}, order = 1)\nNeumannBC(α::AbstractVector{T}, dx::AbstractVector{T}, order = 1)","category":"page"},{"location":"#General-Boundary-Conditions","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"General Boundary Conditions","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Implements a generalization of the Robin boundary condition, where α is a vector of coefficients. Represents a condition of the form α[1] + α[2]u[0] + α[3]u'[0] + α[4]u''[0]+... = 0","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"GeneralBC(αl::AbstractArray{T}, αr::AbstractArray{T}, dx::AbstractArray{T}, order = 1)","category":"page"},{"location":"#Operator-Actions","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Operator Actions","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The boundary condition operators act lazily by appending the appropriate values to the end of the array, building the ghost-point extended version for the derivative operator to act on. This utilizes special array types to not require copying the interior data.","category":"page"},{"location":"#Concretizations-2","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Concretizations","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The following concretizations are provided:","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Array\nSparseMatrixCSC","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Additionally, the function sparse is overloaded to give the most efficient matrix type for a given operator. For these operators it's SparseMatrixCSC. The concretizations are made to act on vec(u).","category":"page"},{"location":"#GhostDerivative-Operators","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"GhostDerivative Operators","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"When L is a DerivativeOperator and Q is a boundary condition operator, L*Q produces a GhostDerivative operator which is the composition of the two operations.","category":"page"},{"location":"#Concretizations-3","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Concretizations","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The following concretizations are provided:","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Array\nSparseMatrixCSC\nBandedMatrix","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Additionally, the function sparse is overloaded to give the most efficient matrix type for a given operator. For these operators it's BandedMatrix unless the boundary conditions are PeriodicBC, in which case it's SparseMatrixCSC. The concretizations are made to act on vec(u).","category":"page"},{"location":"#Matrix-Free-Operators","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Matrix-Free Operators","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"MatrixFreeOperator(f::F, args::N;\n                   size=nothing, opnorm=true, ishermitian=false) where {F,N}","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"A MatrixFreeOperator is a linear operator A*u where the action of A is explicitly defined by an in-place function f(du, u, p, t).","category":"page"},{"location":"#Jacobian-Vector-Product-Operators","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Jacobian-Vector Product Operators","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"JacVecOperator{T}(f,u::AbstractArray,p=nothing,t::Union{Nothing,Number}=nothing;autodiff=true,ishermitian=false,opnorm=true)","category":"page"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"The JacVecOperator is a linear operator J*v where J acts like df/du for some function f(u,p,t). For in-place operations mul!(w,J,v), f is an in-place function f(du,u,p,t).","category":"page"},{"location":"#Operator-Compositions","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Operator Compositions","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Multiplying two DiffEqOperators will build a DiffEqOperatorComposition, while adding two DiffEqOperators will build a DiffEqOperatorCombination. Multiplying a DiffEqOperator by a scalar will produce a DiffEqScaledOperator. All will inherit the appropriate action.","category":"page"},{"location":"#Efficiency-of-Composed-Operator-Actions","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"Efficiency of Composed Operator Actions","text":"","category":"section"},{"location":"","page":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","title":"DiffEqOperators.jl: Linear operators for Scientific Machine Learning","text":"Composed operator actions utilize NNLib.jl in order to do cache-efficient convolution operations in higher-dimensional combinations.","category":"page"}]
}
